{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4134fa4c-f166-4e88-b44b-cb3e92b0c6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from superduperdb import superduper\n",
    "from superduperdb.backends.mongodb import Collection\n",
    "\n",
    "mongodb_uri = os.getenv(\"MONGODB_URI\", \"mongodb://localhost:27017/volvo-demo\")\n",
    "\n",
    "# SuperDuperDB, now handles your MongoDB database\n",
    "# It just super dupers your database \n",
    "db = superduper(mongodb_uri, artifact_store='filesystem://data/artifacts/', downloads_folder='./data/downloads')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a7d5fb-6d46-45b5-b6d3-5daa65d8164c",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef39395-2a98-45b7-a109-d9594c9d7711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduperdb.ext.unstructured.encoder import unstructured_encoder\n",
    "from superduperdb import Document\n",
    "\n",
    "TEST_FILE = \"volvo-GetStarted.pdf\"\n",
    "db.add(unstructured_encoder)\n",
    "collection = Collection('source')\n",
    "to_insert = [Document({\"elements\": unstructured_encoder(TEST_FILE)})]\n",
    "db.execute(collection.insert_many(to_insert))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd9a364-bbce-4e5f-bd2b-dd6e7e48ec02",
   "metadata": {},
   "source": [
    "## Chunk Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc99dade-1534-4dbb-91b3-c01eb64f73b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from superduperdb import Listener, Model, Schema, vector\n",
    "\n",
    "STRIDE = 3  # stride in numbers of lines\n",
    "WINDOW = 10  # length of window in numbers of lines\n",
    "MAX_NUM = 999999999\n",
    "\n",
    "def merge_metadatas(metadatas):\n",
    "\n",
    "    if not metadatas:\n",
    "        return {}\n",
    "    p1, p2, p3, p4 = (MAX_NUM, MAX_NUM), (MAX_NUM, 0), (0, 0), (0, MAX_NUM)\n",
    "    for metadata in metadatas:\n",
    "        p1_, p2_, p3_, p4_ = metadata['coordinates']['points']\n",
    "        p1 = (min(p1[0], p1_[0]), min(p1[1], p1_[1]))\n",
    "        p2 = (min(p2[0], p2_[0]), max(p2[1], p2_[1]))\n",
    "        p3 = (max(p3[0], p3_[0]), max(p3[1], p3_[1]))\n",
    "        p4 = (max(p4[0], p4_[0]), min(p4[1], p4_[1]))\n",
    "    points = (p1, p2, p3, p4)\n",
    "    page_number = metadata['page_number']\n",
    "    return {'points': points, 'page_number': page_number}\n",
    "\n",
    "def create_chunk_and_metadatas(page_elements):\n",
    "    datas = []\n",
    "    for i in range(0, len(page_elements), STRIDE):\n",
    "        windown_elements = page_elements[i : i + WINDOW]\n",
    "        metadatas = [e.metadata.to_dict() for e in windown_elements]\n",
    "        chunk = \"\\n\".join([e.text for e in windown_elements])\n",
    "        datas.append({\"txt\": chunk, 'metadata': merge_metadatas(metadatas)})\n",
    "    return datas\n",
    "\n",
    "def get_chunks(elements):\n",
    "    from collections import defaultdict\n",
    "\n",
    "    pages_elements = defaultdict(list)\n",
    "    for element in elements:\n",
    "        pages_elements[element.metadata.page_number].append(element)\n",
    "\n",
    "    all_chunks_and_links = sum(\n",
    "        [\n",
    "            create_chunk_and_metadatas(page_elements)\n",
    "            for _, page_elements in pages_elements.items()\n",
    "        ],\n",
    "        [],\n",
    "    )\n",
    "    return all_chunks_and_links\n",
    "\n",
    "chunk_model = Model(\n",
    "    identifier=\"chunk\",\n",
    "    object=get_chunks,\n",
    "    flatten=True,\n",
    "    model_update_kwargs={\"document_embedded\": False},\n",
    "    output_schema=Schema(identifier=\"myschema\", fields={\"txt\": \"string\"}),\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "db.add(\n",
    "    Listener(\n",
    "        model=chunk_model,  # Assuming video2images is your SuperDuperDB model\n",
    "        select=collection.find(),\n",
    "        key=\"elements\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6f3e63-a4a1-4041-a59c-e9a8db14694c",
   "metadata": {},
   "source": [
    "## Create a vector-search Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2f50fe-16bc-453d-b47c-11d508213e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentence_transformers\n",
    "from superduperdb import vector, VectorIndex\n",
    "chunk_collection = Collection(\"_outputs.elements.chunk\")\n",
    "\n",
    "model = Model(\n",
    "    identifier=\"embedding\",\n",
    "    object=sentence_transformers.SentenceTransformer(\"BAAI/bge-large-en-v1.5\"),\n",
    "    encoder=vector(shape=(384,)),\n",
    "    predict_method=\"encode\",  # Specify the prediction method\n",
    "    preprocess=lambda x:x['0']['txt'] if isinstance(x, dict) else x,\n",
    "    postprocess=lambda x: x.tolist(),  # Define postprocessing function\n",
    "    batch_predict=True,  # Generate predictions for a set of observations all at once\n",
    ")\n",
    "\n",
    "db.add(\n",
    "    VectorIndex(\n",
    "        # Use a dynamic identifier based on the model's identifier\n",
    "        identifier=\"vector-index\",\n",
    "        # Specify an indexing listener with MongoDB collection and model\n",
    "        indexing_listener=Listener(\n",
    "            select=chunk_collection.find(),\n",
    "            key=\"_outputs.elements.chunk\",  # Key for the documents\n",
    "            model=model,  # Specify the model for processing\n",
    "            predict_kwargs={\"max_chunk_size\": 1000},\n",
    "        ),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec8fcb0-a7c2-40b6-a1ba-4e2c278b387c",
   "metadata": {},
   "source": [
    "## Search Content from PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92836c63-e23f-4b1a-8704-bb18fc6aad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How to call support\"\n",
    "out = db.execute(\n",
    "    chunk_collection.like(\n",
    "        Document({\"_outputs.elements.chunk\": query}),\n",
    "        vector_index=\"vector-index\",\n",
    "        n=5,\n",
    "    ).find({})\n",
    ")\n",
    "\n",
    "for r in sorted(out, key=lambda x:x.content['score'], reverse=True):\n",
    "    print(r.content['score'])\n",
    "    x = r.outputs('elements', 'chunk')['txt']\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8848fe4e-50d0-445c-b7b7-365a3913f153",
   "metadata": {},
   "source": [
    "## QA System For PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1014c5d5-ceed-4422-886e-40741191c778",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduperdb.ext.llm.vllm import VllmModel\n",
    "\n",
    "# Define the prompt for the llm model\n",
    "prompt_template = (\n",
    "    'The following is a document and question about the volvo user manual\\n'\n",
    "    'Only provide a very concise answer\\n'\n",
    "    '{context}\\n\\n'\n",
    "    'Here\\'s the question:{input}\\n'\n",
    "    'answer:'\n",
    ")\n",
    "\n",
    "# Create an instance of llm with the specified model and prompt\n",
    "llm = VllmModel(identifier='llm',\n",
    "                 model_name='mistralai/Mistral-7B-Instruct-v0.2', \n",
    "                 prompt_template=prompt_template,\n",
    "                 vllm_kwargs={\"max_model_len\": 2048}, \n",
    "                 inference_kwargs={\"max_tokens\":2048},\n",
    "               )\n",
    "\n",
    "# Add the llm instance\n",
    "db.add(llm)\n",
    "\n",
    "# Print information about the models in the SuperDuperDB database\n",
    "print(db.show('model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1edef5-4942-4761-94ac-f55064e335de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Log channel is reconnecting. Logs produced while the connection was down can be found on the head node of the cluster in `ray_client_server_[port].out`\n",
      "2024-01-16 15:24:01,885\tWARNING dataclient.py:403 -- Encountered connection issues in the data channel. Attempting to reconnect.\n",
      "2024-01-16 15:24:32,143\tWARNING dataclient.py:410 -- Failed to reconnect the data channel\n"
     ]
    }
   ],
   "source": [
    "from superduperdb import Document\n",
    "\n",
    "# Use the SuperDuperDB model to generate a response based on the search term and context\n",
    "output, sources = db.predict(\n",
    "    model_name='llm',\n",
    "    input=query,\n",
    "    context_select=chunk_collection.like(\n",
    "        Document({\"_outputs.elements.chunk\": query}),\n",
    "        vector_index=\"vector-index\",\n",
    "        n=5,\n",
    "    ).find({}),\n",
    "    context_key='_outputs.elements.chunk.0.txt',\n",
    ")\n",
    "\n",
    "# Get the reference links corresponding to the answer context\n",
    "datas = []\n",
    "page_messages = []\n",
    "for source in sources:\n",
    "    unpack_data = source.unpack()\n",
    "    metadata = unpack_data['metadata']\n",
    "    page_number = metadata['page_number']\n",
    "    points = metadata['points']\n",
    "    score = unpack_data[\"score\"]\n",
    "    message = f\"page_number: {page_number}, score: {score:3f}, coordinates: {points}\"\n",
    "    page_messages.append(message)\n",
    "    \n",
    "\n",
    "# Display the generated response using Markdown\n",
    "print(output.content)\n",
    "print(\"\\n\".join(page_messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ddaab0-c421-4072-8a20-1506f6c75782",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
