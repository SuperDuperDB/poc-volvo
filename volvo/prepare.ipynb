{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaff5723-beee-445e-8838-35667da9e018",
   "metadata": {},
   "source": [
    "# Vector Search and RAG function application based on SuperDuperDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4134fa4c-f166-4e88-b44b-cb3e92b0c6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import click\n",
    "\n",
    "import sentence_transformers\n",
    "from dotenv import load_dotenv\n",
    "from superduperdb import (\n",
    "    Document,\n",
    "    Listener,\n",
    "    Model,\n",
    "    Schema,\n",
    "    VectorIndex,\n",
    "    superduper,\n",
    "    vector,\n",
    ")\n",
    "from superduperdb.backends.mongodb import Collection\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bb7460-069d-4ab1-8781-7211b4a0258a",
   "metadata": {},
   "source": [
    "## Connect to mongodb database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e83996-c889-4596-9a27-487700412554",
   "metadata": {},
   "outputs": [],
   "source": [
    "mongodb_uri = os.getenv(\"MONGODB_URI\", \"superduperdb-demo\")\n",
    "artifact_store = os.getenv(\"ARTIFACT_STORE\", \"data/artifact_store\")\n",
    "\n",
    "db = superduper(mongodb_uri, artifact_store=f\"filesystem://{artifact_store}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e41b23-247d-43fa-ac8b-3f4a28b0ff4c",
   "metadata": {},
   "source": [
    "## Parse pdf files and store them in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6c63e3-8a28-48e6-940a-a5e4bf8e24da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduperdb import Document\n",
    "from superduperdb.ext.unstructured.encoder import unstructured_encoder\n",
    "\n",
    "db.add(unstructured_encoder)\n",
    "\n",
    "pdf_folder = 'pdf-folders'\n",
    "\n",
    "pdf_paths = [os.path.join(pdf_folder, pdf) for pdf in os.listdir(pdf_folder)]\n",
    "collection = Collection(\"source\")\n",
    "to_insert = [\n",
    "    Document({\"elements\": unstructured_encoder(pdf_path)}) for pdf_path in pdf_paths\n",
    "]\n",
    "db.execute(collection.insert_many(to_insert))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc5d0eb-8b85-4f50-a6fb-951932d5e09b",
   "metadata": {},
   "source": [
    "## Create a chunking model to chunk pdf chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1ca929-e6b5-494a-b6e1-f709995128ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_metadatas(metadatas, return_center=False):\n",
    "    MAX_NUM = 999999999\n",
    "    if not metadatas:\n",
    "        return {}\n",
    "    p1, p2, p3, p4 = (MAX_NUM, MAX_NUM), (MAX_NUM, 0), (0, 0), (0, MAX_NUM)\n",
    "    for metadata in metadatas:\n",
    "        p1_, p2_, p3_, p4_ = metadata[\"coordinates\"][\"points\"]\n",
    "        p1 = (min(p1[0], p1_[0]), min(p1[1], p1_[1]))\n",
    "        p2 = (min(p2[0], p2_[0]), max(p2[1], p2_[1]))\n",
    "        p3 = (max(p3[0], p3_[0]), max(p3[1], p3_[1]))\n",
    "        p4 = (max(p4[0], p4_[0]), min(p4[1], p4_[1]))\n",
    "    points = (p1, p2, p3, p4)\n",
    "    if return_center:\n",
    "        points = {\"x\": (p1[0] + p3[0]) / 2, \"y\": (p1[1] + p3[1]) / 2}\n",
    "        page_number = metadata[\"page_number\"]\n",
    "    return {\"points\": points, \"page_number\": page_number}\n",
    "\n",
    "\n",
    "def create_chunk_and_metadatas(page_elements, stride=3, window=10):\n",
    "    datas = []\n",
    "    for i in range(0, len(page_elements), stride):\n",
    "        windown_elements = page_elements[i : i + window]\n",
    "        metadatas = [e.metadata.to_dict() for e in windown_elements]\n",
    "        chunk = \"\\n\".join([e.text for e in windown_elements])\n",
    "        datas.append(\n",
    "            {\"txt\": chunk, \"metadata\": merge_metadatas(metadatas, return_center=True)}\n",
    "        )\n",
    "    return datas\n",
    "\n",
    "\n",
    "def get_chunks(elements):\n",
    "    from collections import defaultdict\n",
    "\n",
    "    pages_elements = defaultdict(list)\n",
    "    for element in elements:\n",
    "        pages_elements[element.metadata.page_number].append(element)\n",
    "\n",
    "    all_chunks_and_links = sum(\n",
    "        [\n",
    "            create_chunk_and_metadatas(page_elements)\n",
    "            for _, page_elements in pages_elements.items()\n",
    "        ],\n",
    "        [],\n",
    "    )\n",
    "    return all_chunks_and_links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4e6123-f8a8-46da-85c1-74882ec4cf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_IDENTIFIER_CHUNK = \"chunk\"\n",
    "chunk_model = Model(\n",
    "    identifier=MODEL_IDENTIFIER_CHUNK,\n",
    "    object=get_chunks,\n",
    "    flatten=True,\n",
    "    model_update_kwargs={\"document_embedded\": False},\n",
    "    output_schema=Schema(identifier=\"myschema\", fields={\"txt\": \"string\"}),\n",
    ")\n",
    "\n",
    "db.add(\n",
    "    Listener(\n",
    "        model=chunk_model,\n",
    "        select=Collection(\"source\").find(),\n",
    "        key=\"elements\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4df45f-c333-403b-8fcb-2bf972aeacc6",
   "metadata": {},
   "source": [
    "## Embedding all text blocks and building vector indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1b5849-a84b-4b7c-8261-5f62e0b30080",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_KEY = \"elements\"\n",
    "MODEL_IDENTIFIER_EMBEDDING = \"embedding\"\n",
    "VECTOR_INDEX_IDENTIFIER = \"vector-index\"\n",
    "COLLECTION_NAME_CHUNK = f\"_outputs.{SOURCE_KEY}.{MODEL_IDENTIFIER_CHUNK}\"\n",
    "CHUNK_OUTPUT_KEY = f\"_outputs.{SOURCE_KEY}.{MODEL_IDENTIFIER_CHUNK}\"\n",
    "\n",
    "chunk_collection = Collection(COLLECTION_NAME_CHUNK)\n",
    "\n",
    "def preprocess(x):\n",
    "    if isinstance(x, dict):\n",
    "        # For model chains, the logic of this key needs to be optimized.\n",
    "        chunk = sorted(x.items())[-1][1]\n",
    "        return chunk[\"txt\"]\n",
    "    return x\n",
    "\n",
    "model = Model(\n",
    "    identifier=MODEL_IDENTIFIER_EMBEDDING,\n",
    "    object=sentence_transformers.SentenceTransformer(\"BAAI/bge-large-en-v1.5\"),\n",
    "    encoder=vector(shape=(384,)),\n",
    "    predict_method=\"encode\",\n",
    "    preprocess=preprocess,\n",
    "    postprocess=lambda x: x.tolist(),\n",
    "    batch_predict=True,\n",
    ")\n",
    "\n",
    "db.add(\n",
    "    VectorIndex(\n",
    "        identifier=VECTOR_INDEX_IDENTIFIER,\n",
    "        indexing_listener=Listener(\n",
    "            select=chunk_collection.find(),\n",
    "            key=CHUNK_OUTPUT_KEY,  # Key for the documents\n",
    "            model=model,  # Specify the model for processing\n",
    "            predict_kwargs={\"max_chunk_size\": 64},\n",
    "        ),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb739534-25f4-48b8-b626-fbbd3049ec9d",
   "metadata": {},
   "source": [
    "## Define a vector search function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32cfd64-3e75-418c-9a85-355d87ccb501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "def vector_search(query, top_k=5):\n",
    "    collection = Collection(COLLECTION_NAME_CHUNK)\n",
    "    out = db.execute(\n",
    "        collection.like(\n",
    "            Document({CHUNK_OUTPUT_KEY: query}),\n",
    "            vector_index=VECTOR_INDEX_IDENTIFIER,\n",
    "            n=top_k,\n",
    "        ).find({})\n",
    "    )\n",
    "    if out:\n",
    "        out = sorted(out, key=lambda x: x.content[\"score\"], reverse=True)\n",
    "    for r in out:\n",
    "        score = r.content[\"score\"]\n",
    "        chunk_data = r.outputs(\"elements\", \"chunk\")\n",
    "        metadata = chunk_data[\"metadata\"]\n",
    "        chunk_message = {}\n",
    "        chunk_message[\"score\"] = score\n",
    "        chunk_message[\"metadata\"] = metadata\n",
    "        txt = chunk_data[\"txt\"]\n",
    "        print(txt)\n",
    "        print()\n",
    "        print(chunk_message)\n",
    "        print(\"\\n\\n\", '-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ab83ac-cfcc-43b2-9ca3-004415acb0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_search(\"What is the function of keys 10 to 12 on the left steering wheel keypad?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15da64e-091c-47ea-9391-aab2a350ffaa",
   "metadata": {},
   "source": [
    "## Define an LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f8571b-c7f2-489b-a36c-a8ef141bdaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_IDENTIFIER_LLM = \"llm\"\n",
    "prompt_template = (\n",
    "    \"The following is a document and question about the volvo user manual\\n\"\n",
    "    \"Only provide a very concise answer\\n\"\n",
    "    \"{context}\\n\\n\"\n",
    "    \"Here's the question:{input}\\n\"\n",
    "    \"answer:\"\n",
    ")\n",
    "\n",
    "from superduperdb.ext.llm.vllm import VllmModel\n",
    "\n",
    "llm = VllmModel(\n",
    "    identifier=MODEL_IDENTIFIER_LLM,\n",
    "    model_name=\"TheBloke/Mistral-7B-Instruct-v0.2-AWQ\",\n",
    "    prompt_template=prompt_template,\n",
    "    vllm_kwargs={\"max_model_len\": 2048, \"quantization\": \"awq\"},\n",
    "    inference_kwargs={\"max_tokens\": 2048},\n",
    ")\n",
    "# Add the llm instance\n",
    "\n",
    "db.add(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0370eb34-25fa-4d20-91a5-cea4b834df99",
   "metadata": {},
   "source": [
    "## Define a QA function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9af14cc-b878-43d4-8cba-eab8786d2186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "def qa(query, vector_search_top_k=5):\n",
    "    collection = Collection(COLLECTION_NAME_CHUNK)\n",
    "    output, out = db.predict(\n",
    "        model_name=MODEL_IDENTIFIER_LLM,\n",
    "        input=query,\n",
    "        context_select=collection.like(\n",
    "            Document({CHUNK_OUTPUT_KEY: query}),\n",
    "            vector_index=VECTOR_INDEX_IDENTIFIER,\n",
    "            n=vector_search_top_k,\n",
    "        ).find({}),\n",
    "        context_key=f\"{CHUNK_OUTPUT_KEY}.0.txt\",\n",
    "    )\n",
    "    if out:\n",
    "        out = sorted(out, key=lambda x: x.content[\"score\"], reverse=True)\n",
    "    page_messages = []\n",
    "    for source in out:\n",
    "        chunk_data = source.outputs(\"elements\", \"chunk\")\n",
    "        metadata = chunk_data[\"metadata\"]\n",
    "        page_number = metadata[\"page_number\"]\n",
    "        points = metadata[\"points\"]\n",
    "        score = source[\"score\"]\n",
    "        page_messages.append(\n",
    "            {\"page_number\": page_number, \"points\": points, \"score\": score}\n",
    "        )\n",
    "    df = pd.DataFrame(page_messages)\n",
    "    display(output.content)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7dd526-fb6f-4363-bdb4-25aac843e3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa(\"What is the function of keys 10 to 12 on the left steering wheel keypad?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
