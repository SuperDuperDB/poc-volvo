{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4134fa4c-f166-4e88-b44b-cb3e92b0c6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhouhaha/workspace/SuperDuperDB/pocs/volvo/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import click\n",
    "\n",
    "import sentence_transformers\n",
    "from dotenv import load_dotenv\n",
    "from superduperdb import (\n",
    "    Document,\n",
    "    Listener,\n",
    "    Model,\n",
    "    Schema,\n",
    "    VectorIndex,\n",
    "    superduper,\n",
    "    vector,\n",
    ")\n",
    "from superduperdb.backends.mongodb import Collection\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bb7460-069d-4ab1-8781-7211b4a0258a",
   "metadata": {},
   "source": [
    "## Connect to mongodb database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07e83996-c889-4596-9a27-487700412554",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-18 16:23:39,570\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m 2024-Jan-18 16:23:39.57\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36m3c87f48a-c135-4be5-adb7-fc0cd3023e5f\u001b[0m| \u001b[36msuperduperdb.base.build\u001b[0m:\u001b[36m60  \u001b[0m | \u001b[1mData Client is ready. MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True, serverselectiontimeoutms=5000)\u001b[0m\n",
      "\u001b[32m 2024-Jan-18 16:23:39.58\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36m3c87f48a-c135-4be5-adb7-fc0cd3023e5f\u001b[0m| \u001b[36msuperduperdb.base.build\u001b[0m:\u001b[36m35  \u001b[0m | \u001b[1mConnecting to Metadata Client with engine:  MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True, serverselectiontimeoutms=5000)\u001b[0m\n",
      "\u001b[32m 2024-Jan-18 16:23:39.58\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36m3c87f48a-c135-4be5-adb7-fc0cd3023e5f\u001b[0m| \u001b[36msuperduperdb.base.datalayer\u001b[0m:\u001b[36m80  \u001b[0m | \u001b[1mBuilding Data Layer\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mongodb_uri = os.getenv(\"MONGODB_URI\", \"superduperdb-demo\")\n",
    "artifact_store = os.getenv(\"ARTIFACT_STORE\", \"data/artifact_store\")\n",
    "\n",
    "db = superduper(mongodb_uri, artifact_store=f\"filesystem://{artifact_store}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e41b23-247d-43fa-ac8b-3f4a28b0ff4c",
   "metadata": {},
   "source": [
    "## Parse pdf files and store them in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e6c63e3-8a28-48e6-940a-a5e4bf8e24da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-18 16:23:41] pikepdf._core INFO pikepdf C++ to Python logger bridge initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m 2024-Jan-18 16:23:43.17\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36m3c87f48a-c135-4be5-adb7-fc0cd3023e5f\u001b[0m| \u001b[36msuperduperdb.backends.local.compute\u001b[0m:\u001b[36m32  \u001b[0m | \u001b[1mSubmitting job. function:<function callable_job at 0x28e631480>\u001b[0m\n",
      "\u001b[32m 2024-Jan-18 16:23:43.18\u001b[0m| \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36m3c87f48a-c135-4be5-adb7-fc0cd3023e5f\u001b[0m| \u001b[36msuperduperdb.backends.local.compute\u001b[0m:\u001b[36m38  \u001b[0m | \u001b[32m\u001b[1mJob submitted.  function:<function callable_job at 0x28e631480> future:7ce3420e-8646-4e79-ad0f-0f4846325a82\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([ObjectId('65a8e00fe2023d47d469d8f6')],\n",
       " TaskWorkflow(database=<superduperdb.base.datalayer.Datalayer object at 0x298dce1d0>, G=<networkx.classes.digraph.DiGraph object at 0x2b36140d0>))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from superduperdb import Document\n",
    "from superduperdb.ext.unstructured.encoder import unstructured_encoder\n",
    "\n",
    "db.add(unstructured_encoder)\n",
    "\n",
    "pdf_folder = 'pdf-folders'\n",
    "\n",
    "pdf_paths = [os.path.join(pdf_folder, pdf) for pdf in os.listdir(pdf_folder)]\n",
    "collection = Collection(\"source\")\n",
    "to_insert = [\n",
    "    Document({\"elements\": unstructured_encoder(pdf_path)}) for pdf_path in pdf_paths\n",
    "]\n",
    "db.execute(collection.insert_many(to_insert))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc5d0eb-8b85-4f50-a6fb-951932d5e09b",
   "metadata": {},
   "source": [
    "## Create a chunking model to chunk pdf chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea1ca929-e6b5-494a-b6e1-f709995128ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_metadatas(metadatas, return_center=False):\n",
    "    MAX_NUM = 999999999\n",
    "    if not metadatas:\n",
    "        return {}\n",
    "    p1, p2, p3, p4 = (MAX_NUM, MAX_NUM), (MAX_NUM, 0), (0, 0), (0, MAX_NUM)\n",
    "    for metadata in metadatas:\n",
    "        p1_, p2_, p3_, p4_ = metadata[\"coordinates\"][\"points\"]\n",
    "        p1 = (min(p1[0], p1_[0]), min(p1[1], p1_[1]))\n",
    "        p2 = (min(p2[0], p2_[0]), max(p2[1], p2_[1]))\n",
    "        p3 = (max(p3[0], p3_[0]), max(p3[1], p3_[1]))\n",
    "        p4 = (max(p4[0], p4_[0]), min(p4[1], p4_[1]))\n",
    "    points = (p1, p2, p3, p4)\n",
    "    if return_center:\n",
    "        points = {\"x\": (p1[0] + p3[0]) / 2, \"y\": (p1[1] + p3[1]) / 2}\n",
    "        page_number = metadata[\"page_number\"]\n",
    "    return {\"points\": points, \"page_number\": page_number}\n",
    "\n",
    "\n",
    "def create_chunk_and_metadatas(page_elements, stride=3, window=10):\n",
    "    datas = []\n",
    "    for i in range(0, len(page_elements), stride):\n",
    "        windown_elements = page_elements[i : i + window]\n",
    "        metadatas = [e.metadata.to_dict() for e in windown_elements]\n",
    "        chunk = \"\\n\".join([e.text for e in windown_elements])\n",
    "        datas.append(\n",
    "            {\"txt\": chunk, \"metadata\": merge_metadatas(metadatas, return_center=True)}\n",
    "        )\n",
    "    return datas\n",
    "\n",
    "\n",
    "def get_chunks(elements):\n",
    "    from collections import defaultdict\n",
    "\n",
    "    pages_elements = defaultdict(list)\n",
    "    for element in elements:\n",
    "        pages_elements[element.metadata.page_number].append(element)\n",
    "\n",
    "    all_chunks_and_links = sum(\n",
    "        [\n",
    "            create_chunk_and_metadatas(page_elements)\n",
    "            for _, page_elements in pages_elements.items()\n",
    "        ],\n",
    "        [],\n",
    "    )\n",
    "    return all_chunks_and_links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed4e6123-f8a8-46da-85c1-74882ec4cf7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 146.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m 2024-Jan-18 16:23:43.32\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36m3c87f48a-c135-4be5-adb7-fc0cd3023e5f\u001b[0m| \u001b[36msuperduperdb.components.model\u001b[0m:\u001b[36m477 \u001b[0m | \u001b[1mAdding 1 model outputs to `db`\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([None],\n",
       " Listener(identifier='chunk/elements', key='elements', model=Model(identifier='chunk', encoder=None, output_schema=Schema(identifier='myschema', fields={'txt': 'string', '_fold': FieldType(identifier='String')}), flatten=True, preprocess=None, postprocess=None, collate_fn=None, batch_predict=False, takes_context=False, metrics=(), model_update_kwargs={'document_embedded': False}, validation_sets=None, predict_X=None, predict_select=None, predict_max_chunk_size=None, predict_kwargs=None, object=<Artifact artifact=<function get_chunks at 0x2b0b75870> serializer=dill>, model_to_device_method=None, metric_values={}, predict_method=None, serializer='dill', device='cpu', preferred_devices=('cuda', 'mps', 'cpu'), training_configuration=None, train_X=None, train_y=None, train_select=None), select=<superduperdb.backends.mongodb.query.MongoCompoundSelect[\n",
       "     \u001b[92m\u001b[1msource.find({'_id': \"{'$in': '[65a8e00fe2023d47d469d8f6]'}\"}, {})\u001b[0m}\n",
       " ] object at 0x2b3649e70>, active=True, predict_kwargs={}))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_IDENTIFIER_CHUNK = \"chunk\"\n",
    "chunk_model = Model(\n",
    "    identifier=MODEL_IDENTIFIER_CHUNK,\n",
    "    object=get_chunks,\n",
    "    flatten=True,\n",
    "    model_update_kwargs={\"document_embedded\": False},\n",
    "    output_schema=Schema(identifier=\"myschema\", fields={\"txt\": \"string\"}),\n",
    ")\n",
    "\n",
    "db.add(\n",
    "    Listener(\n",
    "        model=chunk_model,\n",
    "        select=Collection(\"source\").find(),\n",
    "        key=\"elements\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4df45f-c333-403b-8fcb-2bf972aeacc6",
   "metadata": {},
   "source": [
    "## Embedding all text blocks and building vector indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd1b5849-a84b-4b7c-8261-5f62e0b30080",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-18 16:23:43] sentence_transformers.SentenceTransformer INFO Load pretrained SentenceTransformer: BAAI/bge-large-en-v1.5\n",
      "[2024-01-18 16:23:46] sentence_transformers.SentenceTransformer INFO Use pytorch device: cpu\n",
      "38it [00:00, 11092.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m 2024-Jan-18 16:23:53.15\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36m3c87f48a-c135-4be5-adb7-fc0cd3023e5f\u001b[0m| \u001b[36msuperduperdb.components.model\u001b[0m:\u001b[36m417 \u001b[0m | \u001b[1mComputing chunk 0/0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:14<00:00,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m 2024-Jan-18 16:24:08.08\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36m3c87f48a-c135-4be5-adb7-fc0cd3023e5f\u001b[0m| \u001b[36msuperduperdb.components.model\u001b[0m:\u001b[36m477 \u001b[0m | \u001b[1mAdding 38 model outputs to `db`\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([None],\n",
       " VectorIndex(identifier='vector-index', indexing_listener=Listener(identifier='embedding/elements', key='_outputs.elements.chunk', model=Model(identifier='embedding', encoder=Encoder(identifier='vector[384]', decoder=None, encoder=None, shape=(384,), load_hybrid=True), output_schema=None, flatten=False, preprocess=<Artifact artifact=<function preprocess at 0x2b373cdc0> serializer=dill>, postprocess=<Artifact artifact=<function <lambda> at 0x2b373ce50> serializer=dill>, collate_fn=None, batch_predict=True, takes_context=False, metrics=(), model_update_kwargs={}, validation_sets=None, predict_X=None, predict_select=None, predict_max_chunk_size=None, predict_kwargs=None, object=<Artifact artifact=SentenceTransformer(\n",
       "   (0): Transformer({'max_seq_length': 512, 'do_lower_case': True}) with Transformer model: BertModel \n",
       "   (1): Pooling({'word_embedding_dimension': 1024, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "   (2): Normalize()\n",
       " ) serializer=dill>, model_to_device_method=None, metric_values={}, predict_method='encode', serializer='dill', device='cpu', preferred_devices=('cuda', 'mps', 'cpu'), training_configuration=None, train_X=None, train_y=None, train_select=None), select=<superduperdb.backends.mongodb.query.MongoCompoundSelect[\n",
       "     \u001b[92m\u001b[1m_outputs.elements.chunk.elements.chunk.find({'_id': \"{'$in': '[65a8e00fe2023d47d469d8fc, 65a8e00fe2023d47d469d8fd, 65a8e00fe2023d47d469d8fe, 65a8e00fe2023d47d469d8ff, 65a8e00fe2023d47d469d900, 65a8e00fe2023d47d469d901, 65a8e00fe2023d47d469d902, 65a8e00fe2023d47d469d903, 65a8e00fe2023d47d469d904, 65a8e00fe2023d47d469d905, 65a8e00fe2023d47d469d906, 65a8e00fe2023d47d469d907, 65a8e00fe2023d47d469d908, 65a8e00fe2023d47d469d909, 65a8e00fe2023d47d469d90a, 65a8e00fe2023d47d469d90b, 65a8e00fe2023d47d469d90c, 65a8e00fe2023d47d469d90d, 65a8e00fe2023d47d469d90e, 65a8e00fe2023d47d469d90f, 65a8e00fe2023d47d469d910, 65a8e00fe2023d47d469d911, 65a8e00fe2023d47d469d912, 65a8e00fe2023d47d469d913, 65a8e00fe2023d47d469d914, 65a8e00fe2023d47d469d915, 65a8e00fe2023d47d469d916, 65a8e00fe2023d47d469d917, 65a8e00fe2023d47d469d918, 65a8e00fe2023d47d469d919, 65a8e00fe2023d47d469d91a, 65a8e00fe2023d47d469d91b, 65a8e00fe2023d47d469d91c, 65a8e00fe2023d47d469d91d, 65a8e00fe2023d47d469d91e, 65a8e00fe2023d47d469d91f, 65a8e00fe2023d47d469d920, 65a8e00fe2023d47d469d921]'}\"}, {})\u001b[0m}\n",
       " ] object at 0x2b0c9c880>, active=True, predict_kwargs={'max_chunk_size': 64}), compatible_listener=None, measure=<VectorIndexMeasureType.cosine: 'cosine'>, metric_values={}))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SOURCE_KEY = \"elements\"\n",
    "MODEL_IDENTIFIER_EMBEDDING = \"embedding\"\n",
    "VECTOR_INDEX_IDENTIFIER = \"vector-index\"\n",
    "COLLECTION_NAME_CHUNK = f\"_outputs.{SOURCE_KEY}.{MODEL_IDENTIFIER_CHUNK}\"\n",
    "CHUNK_OUTPUT_KEY = f\"_outputs.{SOURCE_KEY}.{MODEL_IDENTIFIER_CHUNK}\"\n",
    "\n",
    "chunk_collection = Collection(COLLECTION_NAME_CHUNK)\n",
    "\n",
    "def preprocess(x):\n",
    "    if isinstance(x, dict):\n",
    "        # For model chains, the logic of this key needs to be optimized.\n",
    "        chunk = sorted(x.items())[-1][1]\n",
    "        return chunk[\"txt\"]\n",
    "    return x\n",
    "\n",
    "model = Model(\n",
    "    identifier=MODEL_IDENTIFIER_EMBEDDING,\n",
    "    object=sentence_transformers.SentenceTransformer(\"BAAI/bge-large-en-v1.5\"),\n",
    "    encoder=vector(shape=(384,)),\n",
    "    predict_method=\"encode\",\n",
    "    preprocess=preprocess,\n",
    "    postprocess=lambda x: x.tolist(),\n",
    "    batch_predict=True,\n",
    ")\n",
    "\n",
    "db.add(\n",
    "    VectorIndex(\n",
    "        identifier=VECTOR_INDEX_IDENTIFIER,\n",
    "        indexing_listener=Listener(\n",
    "            select=chunk_collection.find(),\n",
    "            key=CHUNK_OUTPUT_KEY,  # Key for the documents\n",
    "            model=model,  # Specify the model for processing\n",
    "            predict_kwargs={\"max_chunk_size\": 64},\n",
    "        ),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb739534-25f4-48b8-b626-fbbd3049ec9d",
   "metadata": {},
   "source": [
    "## Define a vector search function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b32cfd64-3e75-418c-9a85-355d87ccb501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "def vector_search(query, top_k=5):\n",
    "    collection = Collection(COLLECTION_NAME_CHUNK)\n",
    "    out = db.execute(\n",
    "        collection.like(\n",
    "            Document({CHUNK_OUTPUT_KEY: query}),\n",
    "            vector_index=VECTOR_INDEX_IDENTIFIER,\n",
    "            n=top_k,\n",
    "        ).find({})\n",
    "    )\n",
    "    if out:\n",
    "        out = sorted(out, key=lambda x: x.content[\"score\"], reverse=True)\n",
    "    for r in out:\n",
    "        score = r.content[\"score\"]\n",
    "        chunk_data = r.outputs(\"elements\", \"chunk\")\n",
    "        metadata = chunk_data[\"metadata\"]\n",
    "        chunk_message = {}\n",
    "        chunk_message[\"score\"] = score\n",
    "        chunk_message[\"metadata\"] = metadata\n",
    "        txt = chunk_data[\"txt\"]\n",
    "        print(txt)\n",
    "        print()\n",
    "        print(chunk_message)\n",
    "        print(\"\\n\\n\", '-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27ab83ac-cfcc-43b2-9ca3-004415acb0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m 2024-Jan-18 16:24:08.42\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36m3c87f48a-c135-4be5-adb7-fc0cd3023e5f\u001b[0m| \u001b[36msuperduperdb.base.datalayer\u001b[0m:\u001b[36m132 \u001b[0m | \u001b[1mloading of vectors of vector-index: 'vector-index'\u001b[0m\n",
      "\u001b[32m 2024-Jan-18 16:24:08.42\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36m3c87f48a-c135-4be5-adb7-fc0cd3023e5f\u001b[0m| \u001b[36msuperduperdb.base.datalayer\u001b[0m:\u001b[36m166 \u001b[0m | \u001b[1m<superduperdb.backends.mongodb.query.MongoCompoundSelect[\n",
      "    \u001b[92m\u001b[1m_outputs.elements.chunk.elements.chunk.find({'_id': \"{'$in': '[65a8e00fe2023d47d469d8fc, 65a8e00fe2023d47d469d8fd, 65a8e00fe2023d47d469d8fe, 65a8e00fe2023d47d469d8ff, 65a8e00fe2023d47d469d900, 65a8e00fe2023d47d469d901, 65a8e00fe2023d47d469d902, 65a8e00fe2023d47d469d903, 65a8e00fe2023d47d469d904, 65a8e00fe2023d47d469d905, 65a8e00fe2023d47d469d906, 65a8e00fe2023d47d469d907, 65a8e00fe2023d47d469d908, 65a8e00fe2023d47d469d909, 65a8e00fe2023d47d469d90a, 65a8e00fe2023d47d469d90b, 65a8e00fe2023d47d469d90c, 65a8e00fe2023d47d469d90d, 65a8e00fe2023d47d469d90e, 65a8e00fe2023d47d469d90f, 65a8e00fe2023d47d469d910, 65a8e00fe2023d47d469d911, 65a8e00fe2023d47d469d912, 65a8e00fe2023d47d469d913, 65a8e00fe2023d47d469d914, 65a8e00fe2023d47d469d915, 65a8e00fe2023d47d469d916, 65a8e00fe2023d47d469d917, 65a8e00fe2023d47d469d918, 65a8e00fe2023d47d469d919, 65a8e00fe2023d47d469d91a, 65a8e00fe2023d47d469d91b, 65a8e00fe2023d47d469d91c, 65a8e00fe2023d47d469d91d, 65a8e00fe2023d47d469d91e, 65a8e00fe2023d47d469d91f, 65a8e00fe2023d47d469d920, 65a8e00fe2023d47d469d921]'}\"}, {'_outputs.elements.embedding.0': '1', '_outputs.elements.embedding/0': '1', '_id': '1'})\u001b[0m}\n",
      "] object at 0x2b0de1330>\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading vectors into vector-table...: 38it [00:00, 826.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To apply manually, pull the parking brake lever all the way out, past the click.\n",
      "Always check that the symbol in the instrument and the indicator in the lever are illuminated before you leave the cab.\n",
      "Right steering wheel keypad Keys 10 and 11 are used for phone calls. The others are used for navigating in the displays and controlling the infotainment system. The function of each key is the following:\n",
      "1 Navigate left. 2 Navigate up. 3 Navigate right. 4 Navigate down. 5 Select. 6 Return to the home screen. 7 Open a menu. 8 Back. 9 Shift focus between the side display and\n",
      "the instrument display.\n",
      "10 End/Reject a call. 11 Accept a call. 12 Push to talk.\n",
      "Position A is the recommended position for the auxiliary brake. In position A the auxiliary brake is used together with the wheel brakes when the brake pedal is depressed.\n",
      "Gear selector\n",
      "1 Gear lever. Select a drive program (A, M or R) or put the gearbox in neutral (N). 2 Lock button. Hold to allow the gear lever to be moved from neutral (N) to any other drive program (A, M or R).\n",
      "3 +/- button. Shift gear up or down. 4 MODE. Toggle between drive modes.\n",
      "\n",
      "{'score': 0.7726627880280139, 'metadata': {'points': {'x': 1041.2174049999999, 'y': 319.44622500000025}, 'page_number': 1}}\n",
      "\n",
      "\n",
      " --------------------\n",
      "Left steering wheel keypad Keys 10 to 12 control the audio in the truck. The others control cruise control or adaptive cruise control. The function of each key is the following:\n",
      "1 Resume the previously set speed. 2 Increase speed. 3 Decrease speed. 4 Select current speed as set speed. 5 Switch off cruise control or adaptive cruise\n",
      "control.\n",
      "6 Switch on cruise control or adaptive cruise\n",
      "control.\n",
      "7 Activate downhill cruise control. 8 Set the permissible overspeed. 9 Set the distance for adaptive cruise\n",
      "control.\n",
      "10 Mute. 11 Reduce volume. 12 Increase volume.\n",
      "1 Speedometer. 2 Instrument view indicator. Press\n",
      "or change instrument view.\n",
      "\n",
      "{'score': 0.7655553415127412, 'metadata': {'points': {'x': 399.51374, 'y': 349.85872500000005}, 'page_number': 1}}\n",
      "\n",
      "\n",
      " --------------------\n",
      "2 Press the Call key (11) on the right\n",
      "steering wheel keypad.\n",
      "3 Select your phone from the list of\n",
      "available devices that shows up in the display.\n",
      "4 If the number in the display and the\n",
      "number that is shown on your phone match, accept the paring. To pair additional phones or devices, go to Bluetooth in the System Settings menu in the side display.\n",
      "Main switch Before starting the truck, make sure that the main switch is closed. The main switch is located behind the cab.\n",
      "When the main switch is opened, the truck goes directly to function mode \"Parked\". In this mode most consumers are disconnected and the energy consumption from the batteries is minimized.\n",
      "Note that opening the main switch does not disconnect the batteries.\n",
      "Left steering wheel keypad Keys 10 to 12 control the audio in the truck. The others control cruise control or adaptive cruise control. The function of each key is the following:\n",
      "\n",
      "{'score': 0.7266586275969884, 'metadata': {'points': {'x': 207.576865, 'y': 287.1374900000001}, 'page_number': 1}}\n",
      "\n",
      "\n",
      " --------------------\n",
      "available devices that shows up in the display.\n",
      "4 If the number in the display and the\n",
      "number that is shown on your phone match, accept the paring. To pair additional phones or devices, go to Bluetooth in the System Settings menu in the side display.\n",
      "Main switch Before starting the truck, make sure that the main switch is closed. The main switch is located behind the cab.\n",
      "When the main switch is opened, the truck goes directly to function mode \"Parked\". In this mode most consumers are disconnected and the energy consumption from the batteries is minimized.\n",
      "Note that opening the main switch does not disconnect the batteries.\n",
      "Left steering wheel keypad Keys 10 to 12 control the audio in the truck. The others control cruise control or adaptive cruise control. The function of each key is the following:\n",
      "1 Resume the previously set speed. 2 Increase speed. 3 Decrease speed. 4 Select current speed as set speed. 5 Switch off cruise control or adaptive cruise\n",
      "control.\n",
      "6 Switch on cruise control or adaptive cruise\n",
      "\n",
      "{'score': 0.7229473115992184, 'metadata': {'points': {'x': 210.14336500000002, 'y': 287.1374900000001}, 'page_number': 1}}\n",
      "\n",
      "\n",
      " --------------------\n",
      "Main switch Before starting the truck, make sure that the main switch is closed. The main switch is located behind the cab.\n",
      "When the main switch is opened, the truck goes directly to function mode \"Parked\". In this mode most consumers are disconnected and the energy consumption from the batteries is minimized.\n",
      "Note that opening the main switch does not disconnect the batteries.\n",
      "Left steering wheel keypad Keys 10 to 12 control the audio in the truck. The others control cruise control or adaptive cruise control. The function of each key is the following:\n",
      "1 Resume the previously set speed. 2 Increase speed. 3 Decrease speed. 4 Select current speed as set speed. 5 Switch off cruise control or adaptive cruise\n",
      "control.\n",
      "6 Switch on cruise control or adaptive cruise\n",
      "control.\n",
      "7 Activate downhill cruise control. 8 Set the permissible overspeed. 9 Set the distance for adaptive cruise\n",
      "control.\n",
      "\n",
      "{'score': 0.7204746239749801, 'metadata': {'points': {'x': 313.606095, 'y': 252.39644000000013}, 'page_number': 1}}\n",
      "\n",
      "\n",
      " --------------------\n"
     ]
    }
   ],
   "source": [
    "vector_search(\"What is the function of keys 10 to 12 on the left steering wheel keypad?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15da64e-091c-47ea-9391-aab2a350ffaa",
   "metadata": {},
   "source": [
    "## Define an LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8f8571b-c7f2-489b-a36c-a8ef141bdaa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([],\n",
       " OpenAI(encoder=None, output_schema=None, flatten=False, preprocess=None, postprocess=None, collate_fn=None, batch_predict=False, takes_context=True, metrics=(), model_update_kwargs={}, validation_sets=None, predict_X=None, predict_select=None, predict_max_chunk_size=None, predict_kwargs=None, identifier='llm', prompt_template=\"The following is a document and question about the volvo user manual\\nOnly provide a very concise answer\\n{context}\\n\\nHere's the question:{input}\\nanswer:\", prompt_func=None, max_batch_size=4, inference_kwargs={}, api_url='https://api.openai.com/v1', openai_api_base='https://api.openai.com/v1', openai_api_key=None, model_name='gpt-3.5-turbo', chat=True, system_prompt=None, user_role='user', system_role='system'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_IDENTIFIER_LLM = \"llm\"\n",
    "prompt_template = (\n",
    "    \"The following is a document and question about the volvo user manual\\n\"\n",
    "    \"Only provide a very concise answer\\n\"\n",
    "    \"{context}\\n\\n\"\n",
    "    \"Here's the question:{input}\\n\"\n",
    "    \"answer:\"\n",
    ")\n",
    "\n",
    "# from superduperdb.ext.llm.vllm import VllmModel\n",
    "\n",
    "# llm = VllmModel(\n",
    "#     identifier=MODEL_IDENTIFIER_LLM,\n",
    "#     model_name=\"TheBloke/Mistral-7B-Instruct-v0.2-AWQ\",\n",
    "#     prompt_template=prompt_template,\n",
    "#     vllm_kwargs={\"max_model_len\": 2048, \"quantization\": \"awq\"},\n",
    "#     inference_kwargs={\"max_tokens\": 2048},\n",
    "# )\n",
    "# # Add the llm instance\n",
    "\n",
    "from superduperdb.ext.llm.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(identifier=MODEL_IDENTIFIER_LLM, prompt_template=prompt_template)\n",
    "\n",
    "\n",
    "db.add(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0370eb34-25fa-4d20-91a5-cea4b834df99",
   "metadata": {},
   "source": [
    "## Define a QA function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9af14cc-b878-43d4-8cba-eab8786d2186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "def qa(query, vector_search_top_k=5):\n",
    "    collection = Collection(COLLECTION_NAME_CHUNK)\n",
    "    output, out = db.predict(\n",
    "        model_name=MODEL_IDENTIFIER_LLM,\n",
    "        input=query,\n",
    "        context_select=collection.like(\n",
    "            Document({CHUNK_OUTPUT_KEY: query}),\n",
    "            vector_index=VECTOR_INDEX_IDENTIFIER,\n",
    "            n=vector_search_top_k,\n",
    "        ).find({}),\n",
    "        context_key=f\"{CHUNK_OUTPUT_KEY}.0.txt\",\n",
    "    )\n",
    "    if out:\n",
    "        out = sorted(out, key=lambda x: x.content[\"score\"], reverse=True)\n",
    "    page_messages = []\n",
    "    for source in out:\n",
    "        chunk_data = source.outputs(\"elements\", \"chunk\")\n",
    "        metadata = chunk_data[\"metadata\"]\n",
    "        page_number = metadata[\"page_number\"]\n",
    "        points = metadata[\"points\"]\n",
    "        score = source[\"score\"]\n",
    "        page_messages.append(\n",
    "            {\"page_number\": page_number, \"points\": points, \"score\": score}\n",
    "        )\n",
    "    df = pd.DataFrame(page_messages)\n",
    "    display(output.content)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e7dd526-fb6f-4363-bdb4-25aac843e3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m 2024-Jan-18 16:24:08.94\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36m3c87f48a-c135-4be5-adb7-fc0cd3023e5f\u001b[0m| \u001b[36msuperduperdb.ext.llm.base\u001b[0m:\u001b[36m29  \u001b[0m | \u001b[1mInitializing OpenAI : llm\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m 2024-Jan-18 16:24:10.33\u001b[0m| \u001b[1mINFO    \u001b[0m | \u001b[36m183eefeaab2d\u001b[0m| \u001b[36m3c87f48a-c135-4be5-adb7-fc0cd3023e5f\u001b[0m| \u001b[36msuperduperdb.ext.llm.base\u001b[0m:\u001b[36m32  \u001b[0m | \u001b[1mInitialized  OpenAI : llm successfully\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The function of keys 10 to 12 on the left steering wheel keypad is to control the audio in the truck.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>points</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>{'x': 1041.2174049999999, 'y': 319.44622500000...</td>\n",
       "      <td>0.772663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{'x': 399.51374, 'y': 349.85872500000005}</td>\n",
       "      <td>0.765555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>{'x': 207.576865, 'y': 287.1374900000001}</td>\n",
       "      <td>0.726659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>{'x': 210.14336500000002, 'y': 287.1374900000001}</td>\n",
       "      <td>0.722947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>{'x': 313.606095, 'y': 252.39644000000013}</td>\n",
       "      <td>0.720475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number                                             points     score\n",
       "0            1  {'x': 1041.2174049999999, 'y': 319.44622500000...  0.772663\n",
       "1            1          {'x': 399.51374, 'y': 349.85872500000005}  0.765555\n",
       "2            1          {'x': 207.576865, 'y': 287.1374900000001}  0.726659\n",
       "3            1  {'x': 210.14336500000002, 'y': 287.1374900000001}  0.722947\n",
       "4            1         {'x': 313.606095, 'y': 252.39644000000013}  0.720475"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qa(\"What is the function of keys 10 to 12 on the left steering wheel keypad?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e80a60a-a7e3-435a-bdcf-42965e062251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
